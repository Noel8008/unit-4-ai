{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 8.13Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:01, 572kit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 4.42Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [22:48, 364kit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 2.18Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:01, 1.00Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 2.50Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#gpt2.download_gpt2(\n",
    "#    model_name='124M'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name='124M', reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Godzilla gave King Kong the perfect dap and lived happily ever after.\n",
      "\n",
      "The movie was made at The Motion Picture Association of America in New York City.\n",
      "\n",
      "The film was made by the same American company, and directed by Mark Wahlberg, who also directed the movie.\n",
      "\n",
      "The film was made by the same American company, and directed by Mark Wahlberg, who also directed the movie.\n",
      "\n",
      "In the movie, the King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.\n",
      "\n",
      "The King Kong is standing on his throne.<|endoftext|>The Queensland government is considering allowing businesses to use the word \"casper\" in a way that would encourage people to write \"cocaine\" on their shirts after a botched Sydney campaign.\n",
      "\n",
      "The Brisbane Herald reported last week that the government was considering using the phrase to refer to cannabis products.\n",
      "\n",
      "\"It has always been a question of getting people to write this kind of stuff,\" minister for the environment David Keating told the Herald.\n",
      "\n",
      "\"We know the public response has been positive, some of it has been pro-cannabis.\n",
      "\n",
      "\"But it's an advisory, I think, that we're going to do more to try and communicate that to our customers.\"\n",
      "\n",
      "Business leaders and politicians have been quick to defend the use of the word \"casper\" in the context of a campaign that has been criticised as too divisive.\n",
      "\n",
      "\"We're in a bad spot right now with the Greens and the Greens are definitely trying to point out that we have got to do something about the health and wellbeing of people.\n",
      "\n",
      "\"I'm sure we'll get back to them and see what they're saying.\"\n",
      "\n",
      "But Liberal Premier Campbell Newman has singled out the word \"casper\" as \"a bit of a freak word\".\n",
      "\n",
      "\"I think people should all be able to say whatever they want when they want to say it,\" he told the ABC.\n",
      "\n",
      "\"I think this is a great opportunity for our government to be as inclusive as we can and I think it's a good way for us to go.\"\n",
      "\n",
      "The word \"casper\" was used during the campaign, but was criticised when it was used in the context of the Sydney Star, which said it was out of touch with the state's teachings of tolerance.\n",
      "\n",
      "The star said it was \"out of touch\" with the state's teachings of tolerance.\n",
      "\n",
      "\"I think it's really important for us to be able to express that which we have as a state as a whole, and we're not out of touch with what happens in our community,\" Ms Newman said.\n",
      "\n",
      "\"I think there are a lot of people who say that we're out of touch with what happens in our community, and that's ridiculous.\"\n",
      "\n",
      "Mr Keating said he had already been told by the department that the use of the word \"casper\" was not appropriate in the context of the campaign.\n",
      "\n",
      "\"I've looked at the media and I've looked at the media and I've looked at the media and I think that it's clear that we're not out of touch with what happens in our community,\" he said.\n",
      "\n",
      "\"I think we're not out of touch with what happens in our community.\"\n",
      "\n",
      "Topics: drug-offences, law-crime-and-justice, law-crime-and-justice, sydney-2000, nsw\n",
      "\n",
      "First posted<|endoftext|>Election 2016: Austrian Free Trade Agreement\n",
      "\n",
      "Austria's largest foreign direct investment (FDI) organisation, the Austrian Independent Investment Bank (IIMB), has announced an aggressive competition strategy for its flagship Austrian business in Ireland.\n",
      "\n",
      "The bank's new partner, the European Commission, has been a strong supporter of the IIMB's campaign in the United Kingdom and France.\n",
      "\n",
      "It has added that it will build on the political and media consensus of its recent investment in Ireland, which it said will attract a more diverse market.\n",
      "\n",
      "It said that Austria will invest €1 billion (€1.7 billion) from the IIMB to promote the company.\n",
      "\n",
      "\"We are expanding our strategy to attract and retain high-quality talent from across Europe and the world,\" the bank's president, Heinz G. Engelmann, said.\n",
      "\n",
      "The new investment will be based in Ireland, which hosts a large number of foreign direct investment (FDI) firms, the bank said.\n",
      "\n",
      "\"The focus of the investment is on the country's growth, development and competitiveness,\" the bank said.\n",
      "\n",
      "The bank said that in the fifth quarter of\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session,\n",
    "    model_name='124M',          \n",
    "    prefix='Godzilla gave King Kong the perfect dap and lived happily ever after'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakeshake GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547134.425074 27334775 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 19.79] loss=3.86 avg=3.86\n",
      "[2 | 40.17] loss=4.05 avg=3.96\n",
      "[3 | 58.73] loss=3.87 avg=3.93\n",
      "[4 | 77.12] loss=3.62 avg=3.85\n",
      "[5 | 94.96] loss=3.61 avg=3.80\n",
      "[6 | 112.55] loss=3.88 avg=3.81\n",
      "[7 | 130.31] loss=3.70 avg=3.80\n",
      "[8 | 148.17] loss=3.77 avg=3.79\n",
      "[9 | 165.74] loss=3.64 avg=3.78\n",
      "[10 | 182.84] loss=3.66 avg=3.76\n",
      "[11 | 200.59] loss=3.46 avg=3.73\n",
      "[12 | 218.72] loss=3.70 avg=3.73\n",
      "[13 | 236.58] loss=3.37 avg=3.70\n",
      "[14 | 253.72] loss=3.35 avg=3.68\n",
      "[15 | 271.14] loss=3.67 avg=3.68\n",
      "[16 | 288.75] loss=3.58 avg=3.67\n",
      "[17 | 307.06] loss=3.47 avg=3.66\n",
      "[18 | 325.85] loss=3.67 avg=3.66\n",
      "[19 | 343.24] loss=3.60 avg=3.65\n",
      "[20 | 362.32] loss=3.73 avg=3.66\n",
      "[21 | 382.18] loss=3.43 avg=3.65\n",
      "[22 | 402.31] loss=3.36 avg=3.63\n",
      "[23 | 418.91] loss=3.30 avg=3.61\n",
      "[24 | 437.89] loss=3.30 avg=3.60\n",
      "[25 | 455.46] loss=3.40 avg=3.59\n",
      "[26 | 471.91] loss=3.67 avg=3.59\n",
      "[27 | 488.27] loss=3.57 avg=3.59\n",
      "[28 | 505.03] loss=3.66 avg=3.60\n",
      "[29 | 521.08] loss=3.46 avg=3.59\n",
      "[30 | 537.65] loss=3.52 avg=3.59\n",
      "[31 | 553.90] loss=3.50 avg=3.58\n",
      "[32 | 570.79] loss=3.48 avg=3.58\n",
      "[33 | 586.35] loss=3.40 avg=3.57\n",
      "[34 | 602.46] loss=3.37 avg=3.57\n",
      "[35 | 618.60] loss=3.53 avg=3.57\n",
      "[36 | 641.69] loss=3.56 avg=3.57\n",
      "[37 | 661.13] loss=3.27 avg=3.56\n",
      "[38 | 682.38] loss=3.49 avg=3.55\n",
      "[39 | 704.86] loss=3.58 avg=3.56\n",
      "[40 | 726.53] loss=3.52 avg=3.55\n",
      "[41 | 747.94] loss=3.21 avg=3.54\n",
      "[42 | 769.91] loss=3.30 avg=3.54\n",
      "[43 | 789.08] loss=3.71 avg=3.54\n",
      "[44 | 807.46] loss=3.31 avg=3.54\n",
      "[45 | 825.13] loss=3.56 avg=3.54\n",
      "[46 | 843.05] loss=3.09 avg=3.52\n",
      "[47 | 859.70] loss=3.36 avg=3.52\n",
      "[48 | 876.76] loss=3.36 avg=3.52\n",
      "[49 | 894.69] loss=3.35 avg=3.51\n",
      "[50 | 913.45] loss=3.08 avg=3.50\n",
      "[51 | 931.33] loss=3.42 avg=3.50\n",
      "[52 | 948.52] loss=3.15 avg=3.49\n",
      "[53 | 966.97] loss=3.19 avg=3.48\n",
      "[54 | 986.41] loss=3.28 avg=3.48\n",
      "[55 | 1005.40] loss=3.27 avg=3.47\n",
      "[56 | 1023.24] loss=3.29 avg=3.47\n",
      "[57 | 1042.33] loss=3.32 avg=3.46\n",
      "[58 | 1061.09] loss=3.34 avg=3.46\n",
      "[59 | 1078.69] loss=3.21 avg=3.46\n",
      "[60 | 1096.08] loss=3.26 avg=3.45\n",
      "[61 | 1114.10] loss=3.28 avg=3.45\n",
      "[62 | 1131.88] loss=3.08 avg=3.44\n",
      "[63 | 1149.85] loss=3.22 avg=3.44\n",
      "[64 | 1167.39] loss=3.41 avg=3.43\n",
      "[65 | 1184.97] loss=3.26 avg=3.43\n",
      "[66 | 1204.30] loss=3.25 avg=3.43\n",
      "[67 | 1223.32] loss=3.45 avg=3.43\n",
      "[68 | 1241.94] loss=3.14 avg=3.42\n",
      "[69 | 1259.81] loss=3.25 avg=3.42\n",
      "[70 | 1276.88] loss=3.35 avg=3.42\n",
      "[71 | 1295.10] loss=3.29 avg=3.41\n",
      "[72 | 1312.94] loss=3.03 avg=3.41\n",
      "[73 | 1331.13] loss=3.21 avg=3.40\n",
      "[74 | 1349.36] loss=3.02 avg=3.40\n",
      "[75 | 1367.52] loss=3.33 avg=3.39\n",
      "[76 | 1386.09] loss=3.25 avg=3.39\n",
      "[77 | 1404.55] loss=3.21 avg=3.39\n",
      "[78 | 1422.33] loss=3.33 avg=3.39\n",
      "[79 | 1439.68] loss=3.12 avg=3.38\n",
      "[80 | 1457.88] loss=3.24 avg=3.38\n",
      "[81 | 1475.99] loss=3.03 avg=3.37\n",
      "[82 | 1494.76] loss=3.34 avg=3.37\n",
      "[83 | 1513.15] loss=3.05 avg=3.37\n",
      "[84 | 1531.57] loss=3.17 avg=3.36\n",
      "[85 | 1549.50] loss=3.18 avg=3.36\n",
      "[86 | 1568.35] loss=3.18 avg=3.36\n",
      "[87 | 1587.03] loss=2.92 avg=3.35\n",
      "[88 | 1607.12] loss=3.32 avg=3.35\n",
      "[89 | 1626.96] loss=3.13 avg=3.35\n",
      "[90 | 1647.19] loss=2.92 avg=3.34\n",
      "[91 | 1666.63] loss=3.12 avg=3.34\n",
      "[92 | 1686.19] loss=3.17 avg=3.33\n",
      "[93 | 1706.27] loss=3.16 avg=3.33\n",
      "[94 | 1726.27] loss=3.29 avg=3.33\n",
      "[95 | 1746.48] loss=3.11 avg=3.33\n",
      "[96 | 1767.29] loss=3.14 avg=3.32\n",
      "[97 | 1786.78] loss=3.40 avg=3.32\n",
      "[98 | 1808.41] loss=3.32 avg=3.32\n",
      "[99 | 1830.59] loss=2.90 avg=3.32\n",
      "[100 | 1850.88] loss=3.34 avg=3.32\n",
      "Saving checkpoint/shakespear/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    'shakespear.txt',\n",
    "    model_name='124M',\n",
    "    steps=100,\n",
    "    run_name='shakespear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mom said youre adopted \"? I think it had to do with your age.\n",
      "\n",
      "RICHARD:\n",
      "I have no doubt.\n",
      "\n",
      "BUSHY:\n",
      "It must have been a good thing; and the nurse trembled.\n",
      "\n",
      "RICHARD:\n",
      "I think it must have been a good thing; and the nurse trembled.\n",
      "\n",
      "BUSHY:\n",
      "I say it must have been a good thing; and the nurse trembled.\n",
      "\n",
      "RICHARD:\n",
      "I thought it must be a good thing; and the nurse trembled.\n",
      "\n",
      "RICHARD:\n",
      "I thought it must be a good thing; and the nurse trembled.\n",
      "\n",
      "BUSHY:\n",
      "I say it must have been a good thing; and the nurse trembled.\n",
      "\n",
      "RICHARD:\n",
      "Come, come, come, come, this is a nurse's day.\n",
      "\n",
      "BUSHY:\n",
      "You in the garden, sir?\n",
      "\n",
      "RICHARD:\n",
      "The nurse;\n",
      "\n",
      "BUSHY:\n",
      "She in the garden.\n",
      "\n",
      "RICHARD:\n",
      "\n",
      "BUSHY:\n",
      "It is a nurse's day.\n",
      "\n",
      "RICHARD:\n",
      "Now when a nurse is a nurse, you are a nurse.\n",
      "\n",
      "BUSHY:\n",
      "I do not know, sir, but I'll do it.\n",
      "\n",
      "BUSHY:\n",
      "Now when a nurse is a nurse, you are a nurse.\n",
      "\n",
      "RICHARD:\n",
      "You are a nurse, sir, and I am a nurse\n",
      "A nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "I am a nurse, sir, and I am a nurse\n",
      "A nurse.\n",
      "\n",
      "BUSHY:\n",
      "You are a nurse, sir, and I am a nurse\n",
      "A nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse, sir, and I am a nurse\n",
      "A nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse, sir, and I am a nurse\n",
      "A nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "DUKE:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse, sir.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "DUKE:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "DUKE:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSHY:\n",
      "The nurse is a nurse.\n",
      "\n",
      "RICHARD:\n",
      "The nurse is a nurse.\n",
      "\n",
      "BUSH\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix='My mom said youre adopted ',\n",
    "    run_name='shakespear'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
